{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d78ff853",
   "metadata": {
    "id": "5d440bc9-8526-4532-8126-94188dcd41dd"
   },
   "source": [
    "## SetFit ABSA Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0a9e98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed38db62-2707-41d4-b1be-90ec6ee7c787",
   "metadata": {
    "id": "ed38db62-2707-41d4-b1be-90ec6ee7c787"
   },
   "outputs": [],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9555ad2e-f7f4-4611-a337-ecbc75fafad9",
   "metadata": {
    "id": "9555ad2e-f7f4-4611-a337-ecbc75fafad9"
   },
   "outputs": [],
   "source": [
    "!spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cb3ffd",
   "metadata": {},
   "source": [
    "CUDA is required to run SetFit ABSA model, run below code block to check if CUDA is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VX1sWC8bYlt0",
   "metadata": {
    "id": "VX1sWC8bYlt0"
   },
   "outputs": [],
   "source": [
    "# chekc if cuda is available\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0535528",
   "metadata": {},
   "source": [
    "The training dataset we prepared for trainning our own SetFit ABSA model is made available through huggingface. \n",
    "https://huggingface.co/datasets/ginkgogo/ca_restaurants_random_sample We should be able to load the dataset directly from huggingface fter installing required setfit[absa] packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45583a6c-e8da-43a3-a5a0-80f208b2a06f",
   "metadata": {
    "id": "45583a6c-e8da-43a3-a5a0-80f208b2a06f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62.9k/62.9k [00:01<00:00, 56.1kB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f8d2b9da264813bd768eb85249279f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ginkgogo/ca_restaurants_random_sample\", split=\"train\")\n",
    "# splitting dataset into two parts, one for training purposes and the other one for evaluation\n",
    "train_dataset = dataset.select(range(50))\n",
    "eval_dataset = dataset.select(range(50, 102))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "SLIWAXvorYQf",
   "metadata": {
    "id": "SLIWAXvorYQf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'span', 'label', 'ordinal'],\n",
       "    num_rows: 50\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quickly take a look at our training data\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "s2zEMPxprbq4",
   "metadata": {
    "id": "s2zEMPxprbq4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'span', 'label', 'ordinal'],\n",
       "    num_rows: 52\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# also spot on our evaluation data\n",
    "eval_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da685307",
   "metadata": {},
   "source": [
    "Prepare a new instance of Absa model, with selected transformers and spacy large model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16bd84c9-7187-46d7-b96b-439a363a45b0",
   "metadata": {
    "id": "16bd84c9-7187-46d7-b96b-439a363a45b0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9bce4838c6e46a0acdf439d62fa2162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3760026e61f04f008a6d6f60eec887a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from setfit import AbsaModel\n",
    "\n",
    "model = AbsaModel.from_pretrained(\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    \"sentence-transformers/all-mpnet-base-v2\",\n",
    "    spacy_model=\"en_core_web_sm\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d171d48",
   "metadata": {},
   "source": [
    "### Training the SetFitABSA model\n",
    "Prepare training arguments for the ABSA model and passing training dataset and evaluation dataset to the training process. We completed the training using Google Colab and it took about 1 hour using A100 GPU run-time environment. Therefore, we saved this model to huggingface so that we can use it whenever we want without rerun the training. Check \"Using SetFitABSA model\" below for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232260c6-e858-42bd-b96d-101667e5c8e0",
   "metadata": {
    "id": "232260c6-e858-42bd-b96d-101667e5c8e0"
   },
   "outputs": [],
   "source": [
    "from setfit import SetFitModel, Trainer, TrainingArguments, sample_dataset, AbsaTrainer\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"models\",\n",
    "    num_epochs=5,\n",
    "    use_amp=True,\n",
    "    batch_size=50,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    save_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = AbsaTrainer(\n",
    "    model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)],\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1390e237",
   "metadata": {},
   "source": [
    "In order to inspect the model, we use the built-in method provided by the setfit[absa] package to check the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T-TNnSBAkpR8",
   "metadata": {
    "id": "T-TNnSBAkpR8"
   },
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate(eval_dataset)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ROdScmCnmLV-",
   "metadata": {
    "id": "ROdScmCnmLV-"
   },
   "outputs": [],
   "source": [
    "# pip install -U \"huggingface_hub[cli]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040add4f",
   "metadata": {},
   "source": [
    "### Saving the SetFitABSA model to huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "qKAT6dPtmXYi",
   "metadata": {
    "id": "qKAT6dPtmXYi"
   },
   "outputs": [],
   "source": [
    "# uncomment below to login to huggingface\n",
    "# !huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "SN3bKljwlif3",
   "metadata": {
    "id": "SN3bKljwlif3"
   },
   "outputs": [],
   "source": [
    "# uncomment below to save the model to huggingface\n",
    "# model.push_to_hub(\"ginkgogo/setfit-absa-bge-small-en-v1.5-restaurants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f25215",
   "metadata": {},
   "source": [
    "### Using SetFitABSA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h8Pkp-hqrENK",
   "metadata": {
    "id": "h8Pkp-hqrENK"
   },
   "outputs": [],
   "source": [
    "from setfit import AbsaModel\n",
    "\n",
    "# Download from the ðŸ¤— Hub\n",
    "model = AbsaModel.from_pretrained(\n",
    "    \"ginkgogo/setfit-absa-bge-small-en-v1.5-restaurants-aspect\",\n",
    "    \"ginkgogo/setfit-absa-bge-small-en-v1.5-restaurants-polarity\",\n",
    "    spacy_model=\"en_core_web_sm\",\n",
    ")\n",
    "# Run inference\n",
    "preds = model(\"The food was great, but the venue is just way too busy.\")\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LGXqKnN3rU-b",
   "metadata": {
    "id": "LGXqKnN3rU-b"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "  '/content/drive/MyDrive/699/ca_restaurants.csv'\n",
    ")\n",
    "# this is list of business ids that we used in training the SetFit ABSA model, \n",
    "# we need to ommit this from the random sample to avoid bias\n",
    "bus_used_in_train = [234152, 88955, 174286, 228338, 203671, 151156, 88166, 64932, 142804, 210180, 35159, 90839, 137484, 85880, 128479, 92603, 20842, 200330, 175440, 8844, 61777, 3815, 123379, 125840, 180129, 206443, 219869, 101729, 107887, 188230, 244420, 49208, 139902, 242337, 35581, 228649, 44946, 32763, 69556, 152494, 5069963, 3915492, 4486491]\n",
    "\n",
    "random_df_2000 = df.sample(2000)\n",
    "\n",
    "for business in bus_used_in_train:\n",
    "    if business in random_df_2000['business_id']:\n",
    "        random_df_2000.drop(business, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42kb7xANz7oi",
   "metadata": {
    "id": "42kb7xANz7oi"
   },
   "outputs": [],
   "source": [
    "# run inference on the random sample of 2k rows from the California resturant dataset\n",
    "sentences = list(random_df_2000['text'].str.lower())\n",
    "preds = model(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-nsFgsx_zpNu",
   "metadata": {
    "id": "-nsFgsx_zpNu"
   },
   "outputs": [],
   "source": [
    "# quickly inspect model predictions\n",
    "print(preds)\n",
    "print(len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shAW8oCr5B-F",
   "metadata": {
    "id": "shAW8oCr5B-F"
   },
   "outputs": [],
   "source": [
    "# if there's no sentiment extracted, use empty {} as the column value\n",
    "aspects_sentiment = []\n",
    "for i in preds:\n",
    "    if len(i) > 0:\n",
    "        aspects_sentiment.append(i)\n",
    "    else:\n",
    "        aspects_sentiment.append('{}')\n",
    "\n",
    "random_df_2000['aspects_sentiment'] = aspects_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bmcYLrMC8TvY",
   "metadata": {
    "id": "bmcYLrMC8TvY"
   },
   "outputs": [],
   "source": [
    "def extract(aspect_list):\n",
    "    if isinstance(aspect_list, list):\n",
    "        aspect_dict = {}\n",
    "    for aspect in aspect_list:\n",
    "        aspect_dict[aspect['span']] = aspect['polarity']\n",
    "    return aspect_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sQbmmiGU8CFe",
   "metadata": {
    "id": "sQbmmiGU8CFe"
   },
   "outputs": [],
   "source": [
    "# for a in aspects_sentiment:\n",
    "#   if len(a) > 1:\n",
    "#     print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dENJQ9rS68f0",
   "metadata": {
    "id": "dENJQ9rS68f0"
   },
   "outputs": [],
   "source": [
    "random_df_2000['aspects_sentiment'] = random_df_2000['aspects_sentiment'].apply(extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xu521d48-lNZ",
   "metadata": {
    "id": "Xu521d48-lNZ"
   },
   "outputs": [],
   "source": [
    "# random_df_2000[random_df_2000['aspects_sentiment'] != None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XS0ipP3E-ENY",
   "metadata": {
    "id": "XS0ipP3E-ENY"
   },
   "outputs": [],
   "source": [
    "random_df_2000.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58xQBBYiDmoo",
   "metadata": {
    "id": "58xQBBYiDmoo"
   },
   "outputs": [],
   "source": [
    "with_aspect_df = random_df_2000.dropna(subset=['aspects_sentiment'])\n",
    "print(with_aspect_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YPWftyda_WBD",
   "metadata": {
    "id": "YPWftyda_WBD"
   },
   "outputs": [],
   "source": [
    "random_df_2000['aspects_sentiment'] = random_df_2000['aspects_sentiment'].fillna('{}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "epW5pJHF_jEj",
   "metadata": {
    "id": "epW5pJHF_jEj"
   },
   "outputs": [],
   "source": [
    "random_df_2000.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zmL2Bxgm_-uU",
   "metadata": {
    "id": "zmL2Bxgm_-uU"
   },
   "outputs": [],
   "source": [
    "flatten_asepct = pd.json_normalize(random_df_2000['aspects_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZVInKanCCCsZ",
   "metadata": {
    "id": "ZVInKanCCCsZ"
   },
   "outputs": [],
   "source": [
    "aspects = list(flatten_asepct.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0Zq7RKwtB45K",
   "metadata": {
    "id": "0Zq7RKwtB45K"
   },
   "outputs": [],
   "source": [
    "flatten_asepct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dCcbfICk9cDw",
   "metadata": {
    "id": "dCcbfICk9cDw"
   },
   "outputs": [],
   "source": [
    "random_df_2000.reset_index(inplace=True)\n",
    "flatten_asepct.reset_index(inplace=True)\n",
    "final_df = pd.concat([random_df_2000, flatten_asepct], axis=1)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jKgjrm21H6AE",
   "metadata": {
    "id": "jKgjrm21H6AE"
   },
   "outputs": [],
   "source": [
    "print(random_df_2000.shape)\n",
    "print(flatten_asepct.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_G91_LC2IShc",
   "metadata": {
    "id": "_G91_LC2IShc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favPPeD3HkLe",
   "metadata": {
    "id": "favPPeD3HkLe"
   },
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cLhWuToBHFpW",
   "metadata": {
    "id": "cLhWuToBHFpW"
   },
   "outputs": [],
   "source": [
    "# len(final_df.business_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JjHZdfqbFhti",
   "metadata": {
    "id": "JjHZdfqbFhti"
   },
   "outputs": [],
   "source": [
    "with_aspect_df.reset_index(inplace=True)\n",
    "with_aspect_flatten.reset_index(inplace=True)\n",
    "with_aspect_flatten = pd.json_normalize(with_aspect_df['aspects_sentiment'])\n",
    "with_aspect_final_df = pd.concat([with_aspect_df, with_aspect_flatten], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YcjDH4XXG3vv",
   "metadata": {
    "id": "YcjDH4XXG3vv"
   },
   "outputs": [],
   "source": [
    "with_aspect_flatten.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qHuHWjiFGsF2",
   "metadata": {
    "id": "qHuHWjiFGsF2"
   },
   "outputs": [],
   "source": [
    "with_aspect_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B5g2KgBkGmIw",
   "metadata": {
    "id": "B5g2KgBkGmIw"
   },
   "outputs": [],
   "source": [
    "with_aspect_final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GiRJfJBJF209",
   "metadata": {
    "id": "GiRJfJBJF209"
   },
   "outputs": [],
   "source": [
    "with_aspect_final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YOf2NrBMCMKX",
   "metadata": {
    "id": "YOf2NrBMCMKX"
   },
   "outputs": [],
   "source": [
    "# with_aspect_final_df.to_csv('with_aspect_from_random_2k.csv')\n",
    "# !cp with_aspect_from_random_2k.csv '/content/drive/MyDrive/699/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Geo8liLoE5VK",
   "metadata": {
    "id": "Geo8liLoE5VK"
   },
   "outputs": [],
   "source": [
    "# final_df.to_csv('random_2k.csv')\n",
    "# !cp random_2k.csv '/content/drive/MyDrive/699/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bAPylHy3FIqh",
   "metadata": {
    "id": "bAPylHy3FIqh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "out = pd.read_csv('/content/drive/MyDrive/699/with_aspect_from_random_2k.csv')\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZlF0fBiPJEgT",
   "metadata": {
    "id": "ZlF0fBiPJEgT"
   },
   "outputs": [],
   "source": [
    "out_random = pd.read_csv('/content/drive/MyDrive/699/random_2k.csv')\n",
    "out_random.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ade5f1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8524eee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>has_aspects_model_label</th>\n",
       "      <th>aspects_extracted_manual_label</th>\n",
       "      <th>aspect</th>\n",
       "      <th>Model Label</th>\n",
       "      <th>Manual Label</th>\n",
       "      <th>is_actual_restaurant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b_mLN6YOXK50s9id9vA6og</td>\n",
       "      <td>YtDiXgpiP0d5zDmtMEUOow</td>\n",
       "      <td>KC8_Rx4Orlsz8LIonCYXsA</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xobTDm7QNP0RU2CvzUCFBg</td>\n",
       "      <td>B5s_DCLVrBLrL8U6TEVlwA</td>\n",
       "      <td>SsHMgOW3TT48Z7jeV5beqQ</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>service</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xobTDm7QNP0RU2CvzUCFBg</td>\n",
       "      <td>B5s_DCLVrBLrL8U6TEVlwA</td>\n",
       "      <td>SsHMgOW3TT48Z7jeV5beqQ</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>food</td>\n",
       "      <td>not mentioned</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yGwx4jEh9E3XzP-H6fnL-g</td>\n",
       "      <td>UqKi8B6uct0E6WttZI11KA</td>\n",
       "      <td>skY6r8WAkYqpV7_TxNm23w</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yGwx4jEh9E3XzP-H6fnL-g</td>\n",
       "      <td>UqKi8B6uct0E6WttZI11KA</td>\n",
       "      <td>skY6r8WAkYqpV7_TxNm23w</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>service</td>\n",
       "      <td>not mentioned</td>\n",
       "      <td>positive</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  b_mLN6YOXK50s9id9vA6og  YtDiXgpiP0d5zDmtMEUOow  KC8_Rx4Orlsz8LIonCYXsA   \n",
       "1  xobTDm7QNP0RU2CvzUCFBg  B5s_DCLVrBLrL8U6TEVlwA  SsHMgOW3TT48Z7jeV5beqQ   \n",
       "2  xobTDm7QNP0RU2CvzUCFBg  B5s_DCLVrBLrL8U6TEVlwA  SsHMgOW3TT48Z7jeV5beqQ   \n",
       "3  yGwx4jEh9E3XzP-H6fnL-g  UqKi8B6uct0E6WttZI11KA  skY6r8WAkYqpV7_TxNm23w   \n",
       "4  yGwx4jEh9E3XzP-H6fnL-g  UqKi8B6uct0E6WttZI11KA  skY6r8WAkYqpV7_TxNm23w   \n",
       "\n",
       "  has_aspects_model_label aspects_extracted_manual_label   aspect  \\\n",
       "0                       Y                              Y     food   \n",
       "1                       Y                              Y  service   \n",
       "2                       Y                              N     food   \n",
       "3                       Y                              Y     food   \n",
       "4                       Y                              N  service   \n",
       "\n",
       "     Model Label Manual Label is_actual_restaurant  \n",
       "0       positive     positive                    Y  \n",
       "1       positive     negative                    Y  \n",
       "2  not mentioned      neutral                    Y  \n",
       "3       positive     positive                    Y  \n",
       "4  not mentioned     positive                    Y  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load manual evaluation results \n",
    "import pandas as pd\n",
    "setfit_absa_eval_df = pd.read_csv('../data/results/SetFit_ABSA_manual_eval.csv')\n",
    "setfit_absa_eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37bcb9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setfit_absa_eval_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fed33796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of predicting sentiment is : 64.3%\n"
     ]
    }
   ],
   "source": [
    "# calculate when there's an aspect extracted, the accuray of predicting the correct sentiment\n",
    "cal_df = setfit_absa_eval_df[(setfit_absa_eval_df['has_aspects_model_label'] == 'Y') \n",
    "                             & (setfit_absa_eval_df['aspects_extracted_manual_label'] == 'Y')]\n",
    "sentiment_correctness = len(cal_df[cal_df['Model Label'] == cal_df['Manual Label']])/len(cal_df)\n",
    "print('Accuracy of predicting sentiment is :', format(sentiment_correctness, \".1%\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca843be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
